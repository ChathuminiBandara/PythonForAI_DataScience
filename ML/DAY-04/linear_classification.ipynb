{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ba00f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         Review Text  sentiment\n",
      "0  Absolutely wonderful - silky and sexy and comf...          1\n",
      "1  Love this dress!  it's sooo pretty.  i happene...          1\n",
      "2  I love, love, love this jumpsuit. it's fun, fl...          1\n",
      "3  This shirt is very flattering to all due to th...          1\n",
      "4  I love tracy reese dresses, but this one is no...         -1\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 19\u001b[0m\n\u001b[0;32m     14\u001b[0m X_train, X_test, Y_train, Y_test \u001b[38;5;241m=\u001b[39m train_test_split\u001b[38;5;241m.\u001b[39mtrain_test_split(X, Y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, stratify\u001b[38;5;241m=\u001b[39mY)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# stratify is used to maintain the distribution of the target variable in both training and testing sets , positive and negative reviews in this case\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# initialize the vectorizer, 'stop words  'remove the common english words that do not contribute to the meaning of the text\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# such as 'the', 'is', 'and', etc.\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m vectorizer \u001b[38;5;241m=\u001b[39m \u001b[43mCountVectorizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstop_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43menglish\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# fit the vectorizer on the training data and transform it into a matrix\u001b[39;00m\n\u001b[0;32m     22\u001b[0m X_train_bow \u001b[38;5;241m=\u001b[39m vectorizer\u001b[38;5;241m.\u001b[39mfit_transform(X_train)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sklearn.model_selection as train_test_split\n",
    "import sklearn.feature_extraction.text as CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score \n",
    "\n",
    "df = pd.read_csv('womens_clothing_ecommerce_reviews.csv')\n",
    "print(df.head())\n",
    "\n",
    "X = df[[\"Review Text\"]]\n",
    "Y = df[[\"sentiment\"]]\n",
    "\n",
    "# \"stratify\" ensures that the proprtion of positive and negative reviews is maintained in both training and testing sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split.train_test_split(X, Y, test_size=0.2, random_state=42, stratify=Y)\n",
    "# stratify is used to maintain the distribution of the target variable in both training and testing sets , positive and negative reviews in this case\n",
    "\n",
    "# initialize the vectorizer, 'stop words  'remove the common english words that do not contribute to the meaning of the text\n",
    "# such as 'the', 'is', 'and', etc.\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "\n",
    "# fit the vectorizer on the training data and transform it into a matrix\n",
    "X_train_bow = vectorizer.fit_transform(X_train)\n",
    "\n",
    "# only transform the testing data using the already-fitted vectorizer\n",
    "X_test_bow = vectorizer.transform(X_test)\n",
    "\n",
    "# initialize the logistic regression model\n",
    "# max_iter is increased to ensure the model has enough time to fid the bst weights\n",
    "model = LogisticRegression(max_iter=2000)\n",
    "\n",
    "# train the model on your bag-of-words representation of the training data\n",
    "model.fit(X_train_bow, Y_train)\n",
    "\n",
    "print(\"Model trained successfully!\")\n",
    "\n",
    "#make predictions on the test data\n",
    "Y_pred = model.predict(X_test_bow)\n",
    "\n",
    "# calculate the accuracy of the model\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "print(f\"Model accuracy: {accuracy:.4f} ({accuracy:.2%})\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2bc8bcb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         Review Text  sentiment\n",
      "0  Absolutely wonderful - silky and sexy and comf...          1\n",
      "1  Love this dress!  it's sooo pretty.  i happene...          1\n",
      "2  I love, love, love this jumpsuit. it's fun, fl...          1\n",
      "3  This shirt is very flattering to all due to th...          1\n",
      "4  I love tracy reese dresses, but this one is no...         -1\n",
      "Model trained successfully!\n",
      "Model accuracy: 0.9294 (92.94%)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "df = pd.read_csv('womens_clothing_ecommerce_reviews.csv')\n",
    "print(df.head())\n",
    "\n",
    "# Use 1D Series for X and y\n",
    "X = df[\"Review Text\"]\n",
    "Y = df[\"sentiment\"]\n",
    "\n",
    "# stratify keeps the class distribution\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X, Y, test_size=0.2, random_state=42, stratify=Y\n",
    ")\n",
    "\n",
    "# vectorize text\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "X_train_bow = vectorizer.fit_transform(X_train)\n",
    "X_test_bow = vectorizer.transform(X_test)\n",
    "\n",
    "# train model\n",
    "model = LogisticRegression(max_iter=2000)\n",
    "model.fit(X_train_bow, Y_train)\n",
    "\n",
    "print(\"Model trained successfully!\")\n",
    "\n",
    "# evaluate\n",
    "Y_pred = model.predict(X_test_bow)\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "print(f\"Model accuracy: {accuracy:.4f} ({accuracy:.2%})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c4216b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chath\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained successfully!\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 2 features, but LogisticRegression is expecting 11897 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 36\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel trained successfully!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# evaluate\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m Y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_reviews_bow\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(Y_test, Y_pred)\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2%\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\chath\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:375\u001b[0m, in \u001b[0;36mLinearClassifierMixin.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    362\u001b[0m \u001b[38;5;124;03mPredict class labels for samples in X.\u001b[39;00m\n\u001b[0;32m    363\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    372\u001b[0m \u001b[38;5;124;03m    Vector containing the class labels for each sample.\u001b[39;00m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    374\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[1;32m--> 375\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(scores\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    377\u001b[0m     indices \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(scores \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, indexing_dtype(xp))\n",
      "File \u001b[1;32mc:\\Users\\chath\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:352\u001b[0m, in \u001b[0;36mLinearClassifierMixin.decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    349\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    350\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[1;32m--> 352\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    353\u001b[0m scores \u001b[38;5;241m=\u001b[39m safe_sparse_dot(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    355\u001b[0m     xp\u001b[38;5;241m.\u001b[39mreshape(scores, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,))\n\u001b[0;32m    356\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (scores\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m scores\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    357\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m scores\n\u001b[0;32m    358\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\chath\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2975\u001b[0m, in \u001b[0;36mvalidate_data\u001b[1;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[0;32m   2972\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m   2974\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m-> 2975\u001b[0m     \u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_estimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2977\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\chath\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2839\u001b[0m, in \u001b[0;36m_check_n_features\u001b[1;34m(estimator, X, reset)\u001b[0m\n\u001b[0;32m   2836\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   2838\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m estimator\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[1;32m-> 2839\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2840\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2841\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2842\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 2 features, but LogisticRegression is expecting 11897 features as input."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('womens_clothing_ecommerce_reviews.csv')\n",
    "print(df.head())\n",
    "\n",
    "# Features and target as 1D Series\n",
    "X = df[\"Review Text\"]\n",
    "Y = df[\"sentiment\"]\n",
    "\n",
    "# Split (with stratification to keep class balance)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X, Y, test_size=0.2, random_state=42, stratify=Y\n",
    ")\n",
    "\n",
    "# Vectorize text\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "X_train_bow = vectorizer.fit_transform(X_train)\n",
    "X_test_bow = vectorizer.transform(X_test)\n",
    "\n",
    "# Train model\n",
    "model = LogisticRegression(max_iter=2000)\n",
    "model.fit(X_train_bow, Y_train)\n",
    "\n",
    "print(\"Model trained successfully!\")\n",
    "\n",
    "# Evaluate\n",
    "Y_pred = model.predict(X_test_bow)\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "print(f\"Model accuracy: {accuracy:.4f} ({accuracy:.2%})\")\n",
    "\n",
    "# --- New reviews prediction ---\n",
    "reviews = [\n",
    "    \"I absolutely love this dress\",\n",
    "    \"This shirt is terrible.\",\n",
    "    \"Great quality !\",\n",
    "    \"The shoes are okay\"\n",
    "]\n",
    "\n",
    "# Vectorize the new reviews\n",
    "new_reviews_bow = vectorizer.transform(reviews)\n",
    "\n",
    "# Predict sentiments and probabilities\n",
    "new_predictions = model.predict(new_reviews_bow)\n",
    "probs = model.predict_proba(new_reviews_bow)\n",
    "\n",
    "# Optional: map numeric labels to readable strings if needed\n",
    "# e.g., if sentiment is 1=positive, 0=negative\n",
    "label_map = {1: \"positive\", 0: \"negative\"}\n",
    "\n",
    "for review, pred, prob in zip(reviews, new_predictions, probs):\n",
    "    readable = label_map.get(pred, pred)\n",
    "    confidence = max(prob)\n",
    "    print(f\"Review: {review!r}\")\n",
    "    print(f\"  Predicted sentiment: {readable} (confidence: {confidence:.2%})\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
